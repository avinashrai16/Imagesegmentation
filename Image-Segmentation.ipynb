{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "U-Net (TensorFlow/Keras) on Pascal VOC",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\n# Example function to build U-Net model\ndef build_unet(input_shape=(128, 128, 3)):\n    inputs = layers.Input(input_shape)\n    \n    # Contracting path (Encoder)\n    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n    p1 = layers.MaxPooling2D((2, 2))(c1)\n    \n    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n    p2 = layers.MaxPooling2D((2, 2))(c2)\n\n    # Bottleneck\n    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n\n    # Expanding path (Decoder)\n    u1 = layers.UpSampling2D((2, 2))(c3)\n    u1 = layers.Concatenate()([u1, c2])\n    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u1)\n    c4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4)\n\n    u2 = layers.UpSampling2D((2, 2))(c4)\n    u2 = layers.Concatenate()([u2, c1])\n    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u2)\n    c5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5)\n    \n    outputs = layers.Conv2D(21, (1, 1), activation='softmax')(c5)  # 21 classes for Pascal VOC\n    \n    model = models.Model(inputs, outputs)\n    return model\n\n# Load dataset (replace with your own data loader for Pascal VOC)\ndef load_pascal_voc():\n    # Here you should load your Pascal VOC dataset (e.g., using tfds or manual data loading)\n    pass\n\n# Model compilation and training\nmodel = build_unet()\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Load your dataset here (Pascal VOC)\n# x_train, y_train = load_pascal_voc()\n\n# Train the model\n# model.fit(x_train, y_train, batch_size=32, epochs=50)\n\n# Evaluate the model (use the test set)\n# test_loss, test_acc = model.evaluate(x_test, y_test)\n# print(f\"Test accuracy: {test_acc:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Mask R-CNN (PyTorch) on COCO",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Load pre-trained Mask R-CNN model\nmodel = models.detection.maskrcnn_resnet50_fpn(pretrained=True)\nmodel.eval()\n\n# Load and preprocess image\ndef load_and_preprocess_image(image_path):\n    transform = transforms.Compose([transforms.ToTensor()])\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image)\n    return image.unsqueeze(0)  # Add batch dimension\n\n# Example: Load COCO image\nimage = load_and_preprocess_image('path_to_your_image.jpg')\n\n# Perform segmentation\nwith torch.no_grad():\n    prediction = model(image)\n\n# Extract masks and plot\nmasks = prediction[0]['masks']  # Shape [num_objects, height, width]\nlabels = prediction[0]['labels']\nscores = prediction[0]['scores']\n\n# Display the first mask (if there are any detections)\nif len(masks) > 0:\n    mask = masks[0, 0]  # Mask for the first detected object\n    plt.imshow(mask.cpu().numpy(), cmap='gray')\n    plt.title(f\"Detected Class: {labels[0]} with Score: {scores[0]:.4f}\")\n    plt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Evaluating Performance by measuring accuracy, IoU, AP, etc.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pycocotools.coco import COCO\n\n# Load COCO ground truth and results\ncoco_gt = COCO('annotations/instances_val2017.json')\ncoco_dt = coco_gt.loadRes('predictions.json')  # Load your model's prediction results\n\n# Evaluate performance\ncoco_eval = COCOeval(coco_gt, coco_dt, 'segm')\ncoco_eval.evaluate()\ncoco_eval.accumulate()\ncoco_eval.summarize()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}